{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e8d85e0",
   "metadata": {
    "papermill": {
     "duration": 0.008495,
     "end_time": "2023-11-22T06:32:58.000091",
     "exception": false,
     "start_time": "2023-11-22T06:32:57.991596",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "* This is worth mentioning that the Public LB for this competition is highly overfitted since you can see the test set is so small. Even including a text preprocessing (which is a standard process) pipeline is decreasing the score on the LB. So I would like to advise all the people who are directly forking and making the submissions to not completely rely on these notebooks. Try making more robust models with text cleaning and preprocessing functions, better text encoders like Word2Vec, BERT and better models like LSTMs (Sequential) or GNNs (Graph-Based) so that you have a good score in the Private LB as well.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67fa25b3",
   "metadata": {
    "papermill": {
     "duration": 0.0071,
     "end_time": "2023-11-22T06:32:58.014987",
     "exception": false,
     "start_time": "2023-11-22T06:32:58.007887",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "* The next few notebooks I'll publish will be having better models and text preprocessing pipelines. Just a heads up, I have made some submissions with a private notebook and the scores are not good, but we'll see that these notebooks will score higher on the Private LB."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcbff86f",
   "metadata": {
    "papermill": {
     "duration": 0.007124,
     "end_time": "2023-11-22T06:32:58.030145",
     "exception": false,
     "start_time": "2023-11-22T06:32:58.023021",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Importing library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "688c3d2e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-22T06:32:58.047798Z",
     "iopub.status.busy": "2023-11-22T06:32:58.047372Z",
     "iopub.status.idle": "2023-11-22T06:33:25.145860Z",
     "shell.execute_reply": "2023-11-22T06:33:25.144611Z"
    },
    "papermill": {
     "duration": 27.110614,
     "end_time": "2023-11-22T06:33:25.148727",
     "exception": false,
     "start_time": "2023-11-22T06:32:58.038113",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -q language-tool-python --no-index --find-links ../input/daigt-misc/\n",
    "!mkdir -p /root/.cache/language_tool_python/\n",
    "!cp -r /kaggle/input/daigt-misc/lang57/LanguageTool-5.7 /root/.cache/language_tool_python/LanguageTool-5.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68936453",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-22T06:33:25.165751Z",
     "iopub.status.busy": "2023-11-22T06:33:25.165352Z",
     "iopub.status.idle": "2023-11-22T06:33:28.405669Z",
     "shell.execute_reply": "2023-11-22T06:33:28.404679Z"
    },
    "papermill": {
     "duration": 3.252205,
     "end_time": "2023-11-22T06:33:28.408362",
     "exception": false,
     "start_time": "2023-11-22T06:33:25.156157",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.metrics import make_scorer, accuracy_score\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import language_tool_python\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "seed = 202"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a88aa90",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-22T06:33:28.425551Z",
     "iopub.status.busy": "2023-11-22T06:33:28.424926Z",
     "iopub.status.idle": "2023-11-22T06:33:31.054055Z",
     "shell.execute_reply": "2023-11-22T06:33:31.052967Z"
    },
    "papermill": {
     "duration": 2.641138,
     "end_time": "2023-11-22T06:33:31.057032",
     "exception": false,
     "start_time": "2023-11-22T06:33:28.415894",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"/kaggle/input/daigt-v2-train-dataset/train_v2_drcat_02.csv\")\n",
    "external_train = pd.read_csv(\"/kaggle/input/llm-detect-ai-generated-text/train_essays.csv\")\n",
    "external_train.rename(columns={'generated': 'label'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0044573a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-22T06:33:31.074967Z",
     "iopub.status.busy": "2023-11-22T06:33:31.074013Z",
     "iopub.status.idle": "2023-11-22T06:33:31.080464Z",
     "shell.execute_reply": "2023-11-22T06:33:31.079272Z"
    },
    "papermill": {
     "duration": 0.017923,
     "end_time": "2023-11-22T06:33:31.082986",
     "exception": false,
     "start_time": "2023-11-22T06:33:31.065063",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed=202):\n",
    "    import random\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "seed_everything(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cee5632",
   "metadata": {
    "papermill": {
     "duration": 0.008055,
     "end_time": "2023-11-22T06:33:31.104391",
     "exception": false,
     "start_time": "2023-11-22T06:33:31.096336",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Data Imports and Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a4404bb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-22T06:33:31.122281Z",
     "iopub.status.busy": "2023-11-22T06:33:31.121093Z",
     "iopub.status.idle": "2023-11-22T06:33:34.256321Z",
     "shell.execute_reply": "2023-11-22T06:33:34.254767Z"
    },
    "papermill": {
     "duration": 3.147492,
     "end_time": "2023-11-22T06:33:34.259760",
     "exception": false,
     "start_time": "2023-11-22T06:33:31.112268",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tool = language_tool_python.LanguageTool('en-US')\n",
    "def correct_sentence(sentence):\n",
    "    return tool.correct(sentence)\n",
    "def correct_df(df):\n",
    "    with ProcessPoolExecutor() as executor:\n",
    "        df['text'] = list(executor.map(correct_sentence, df['text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "095fad5e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-22T06:33:34.282707Z",
     "iopub.status.busy": "2023-11-22T06:33:34.282297Z",
     "iopub.status.idle": "2023-11-22T06:33:34.289107Z",
     "shell.execute_reply": "2023-11-22T06:33:34.287881Z"
    },
    "papermill": {
     "duration": 0.021398,
     "end_time": "2023-11-22T06:33:34.291920",
     "exception": false,
     "start_time": "2023-11-22T06:33:34.270522",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def how_many_typos(text):    \n",
    "    return len(tool.check(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5604ae7c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-22T06:33:34.309005Z",
     "iopub.status.busy": "2023-11-22T06:33:34.308544Z",
     "iopub.status.idle": "2023-11-22T06:33:36.629206Z",
     "shell.execute_reply": "2023-11-22T06:33:36.627784Z"
    },
    "papermill": {
     "duration": 2.332154,
     "end_time": "2023-11-22T06:33:36.631843",
     "exception": false,
     "start_time": "2023-11-22T06:33:34.299689",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚕🙄💪💊こ🎥🐬止🔜🍋😔ま╯—🍳👮🐰😤🎾安🎠🐶👥😡👫护💫🐢🤒🚔📸💧🤣🏆📄时路🥔п用📖🍓🤤💁🌿🏛择🌱🙊注🇺🌯😖🐱🔥🥨🐾机💭🎓中🧹👕🙋应🇫驾🍜🤯🏈🥜🧀💥🔑🙀🤩÷🔭🧚🚪а💖🤖👯🙃手🏀响🏕💡🔋🤝🦄🌊🏳🏨♀🏦保ã全🤔😈🤫🍴😮🏢🧠🏯…д👪👧🥳🕵🇵🐆💼з该🏫🚣🕒�。🌲^😘🦐🧖🥦’🎨🚭📺🥟✨🏜力🌠🤪合🎉💅う💨🍗😝🌫💯🍣都🤕ち😃💬🏼🥘🧽🌐👌💤🏄🍷🍲🎩🌭🎵😊–🥑💦📦í👂🍭😩使🌞🏰🍟”🤘😷😳🥗“📝🐳意💰🇯ç🗣🌧ん🍁🐒🧦🤷🐭🌃が🏊🌽🏃😜🥶🔧💉🏖📊⚽📚🎧🏋🙅🧐😄🇸🏟🎶🛬🏽所🚗🔬🙌😋🌨在🤛🙏😻👀😁🏙🌅🏏🦁🛣сê🇪😱─🌎🦸あ🎅😉💘🤗🧑🥛🏻💔🐕🥤💚💸🗳🎬🕹法🤞🍎🔍🌟😍🍝🍖的📈👏和🐸📷取­🚨е🤓📉🚀に🎤一¬\n"
     ]
    }
   ],
   "source": [
    "not_persuade_df = train[train['source'] != 'persuade_corpus']\n",
    "persuade_df = train[train['source'] == 'persuade_corpus']\n",
    "sampled_persuade_df = persuade_df.sample(n=6000, random_state=42)\n",
    "# Testing idea from discussion with @nbroad about limited characters in human essays\n",
    "all_human = set(list(''.join(sampled_persuade_df.text.to_list())))\n",
    "other = set(list(''.join(not_persuade_df.text.to_list())))\n",
    "chars_to_remove = ''.join([x for x in other if x not in all_human])\n",
    "print(chars_to_remove)\n",
    "\n",
    "translation_table = str.maketrans('', '', chars_to_remove)\n",
    "def remove_chars(s):\n",
    "    return s.translate(translation_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "150a7c1d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-22T06:33:36.648824Z",
     "iopub.status.busy": "2023-11-22T06:33:36.648390Z",
     "iopub.status.idle": "2023-11-22T06:33:48.693917Z",
     "shell.execute_reply": "2023-11-22T06:33:48.692058Z"
    },
    "papermill": {
     "duration": 12.057972,
     "end_time": "2023-11-22T06:33:48.697454",
     "exception": false,
     "start_time": "2023-11-22T06:33:36.639482",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train=pd.concat([train,external_train])\n",
    "train['text'] = train['text'].apply(remove_chars)\n",
    "train['text'] = train['text'].str.replace('\\n', '')\n",
    "\n",
    "test = pd.read_csv('/kaggle/input/llm-detect-ai-generated-text/test_essays.csv')\n",
    "test['text'] = test['text'].str.replace('\\n', '')\n",
    "test['text'] = test['text'].apply(remove_chars)\n",
    "correct_df(test)\n",
    "df = pd.concat([train['text'], test['text']], axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b287058f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-22T06:33:48.719313Z",
     "iopub.status.busy": "2023-11-22T06:33:48.718836Z",
     "iopub.status.idle": "2023-11-22T06:33:49.538515Z",
     "shell.execute_reply": "2023-11-22T06:33:49.536660Z"
    },
    "papermill": {
     "duration": 0.831721,
     "end_time": "2023-11-22T06:33:49.540671",
     "exception": true,
     "start_time": "2023-11-22T06:33:48.708950",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 're' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m vectorizer \u001b[38;5;241m=\u001b[39m TfidfVectorizer(ngram_range\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m6\u001b[39m),tokenizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: re\u001b[38;5;241m.\u001b[39mfindall(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[^\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mW]+\u001b[39m\u001b[38;5;124m'\u001b[39m, x),token_pattern\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,strip_accents\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124municode\u001b[39m\u001b[38;5;124m'\u001b[39m,)\n\u001b[0;32m----> 2\u001b[0m vectorizer \u001b[38;5;241m=\u001b[39m \u001b[43mvectorizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m X \u001b[38;5;241m=\u001b[39m vectorizer\u001b[38;5;241m.\u001b[39mtransform(df)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:2103\u001b[0m, in \u001b[0;36mTfidfVectorizer.fit\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   2096\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_warn_for_unused_params()\n\u001b[1;32m   2097\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tfidf \u001b[38;5;241m=\u001b[39m TfidfTransformer(\n\u001b[1;32m   2098\u001b[0m     norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm,\n\u001b[1;32m   2099\u001b[0m     use_idf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_idf,\n\u001b[1;32m   2100\u001b[0m     smooth_idf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msmooth_idf,\n\u001b[1;32m   2101\u001b[0m     sublinear_tf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msublinear_tf,\n\u001b[1;32m   2102\u001b[0m )\n\u001b[0;32m-> 2103\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_documents\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2104\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tfidf\u001b[38;5;241m.\u001b[39mfit(X)\n\u001b[1;32m   2105\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1388\u001b[0m, in \u001b[0;36mCountVectorizer.fit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1380\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   1381\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUpper case characters found in\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1382\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m vocabulary while \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlowercase\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1383\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is True. These entries will not\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1384\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m be matched with any documents\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1385\u001b[0m             )\n\u001b[1;32m   1386\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m-> 1388\u001b[0m vocabulary, X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_count_vocab\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_documents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfixed_vocabulary_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1390\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbinary:\n\u001b[1;32m   1391\u001b[0m     X\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mfill(\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1275\u001b[0m, in \u001b[0;36mCountVectorizer._count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m   1273\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m raw_documents:\n\u001b[1;32m   1274\u001b[0m     feature_counter \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m-> 1275\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m feature \u001b[38;5;129;01min\u001b[39;00m \u001b[43manalyze\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1276\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1277\u001b[0m             feature_idx \u001b[38;5;241m=\u001b[39m vocabulary[feature]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:113\u001b[0m, in \u001b[0;36m_analyze\u001b[0;34m(doc, analyzer, tokenizer, ngrams, preprocessor, decoder, stop_words)\u001b[0m\n\u001b[1;32m    111\u001b[0m     doc \u001b[38;5;241m=\u001b[39m preprocessor(doc)\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tokenizer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 113\u001b[0m     doc \u001b[38;5;241m=\u001b[39m \u001b[43mtokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ngrams \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stop_words \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[0;32m----> 1\u001b[0m vectorizer \u001b[38;5;241m=\u001b[39m TfidfVectorizer(ngram_range\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m6\u001b[39m),tokenizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mre\u001b[49m\u001b[38;5;241m.\u001b[39mfindall(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[^\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mW]+\u001b[39m\u001b[38;5;124m'\u001b[39m, x),token_pattern\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,strip_accents\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124municode\u001b[39m\u001b[38;5;124m'\u001b[39m,)\n\u001b[1;32m      2\u001b[0m vectorizer \u001b[38;5;241m=\u001b[39m vectorizer\u001b[38;5;241m.\u001b[39mfit(test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      3\u001b[0m X \u001b[38;5;241m=\u001b[39m vectorizer\u001b[38;5;241m.\u001b[39mtransform(df)\n",
      "\u001b[0;31mNameError\u001b[0m: name 're' is not defined"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(ngram_range=(3, 6),tokenizer=lambda x: re.findall(r'[^\\W]+', x),token_pattern=None,strip_accents='unicode',)\n",
    "vectorizer = vectorizer.fit(test['text'])\n",
    "X = vectorizer.transform(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecea4d5c",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2b9077",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-21T08:52:04.347409Z",
     "iopub.status.busy": "2023-11-21T08:52:04.347135Z",
     "iopub.status.idle": "2023-11-21T08:52:04.352183Z",
     "shell.execute_reply": "2023-11-21T08:52:04.351281Z",
     "shell.execute_reply.started": "2023-11-21T08:52:04.347386Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "lr=LogisticRegression()\n",
    "clf = MultinomialNB(alpha=0.02)\n",
    "sgd_model = SGDClassifier(max_iter=5000, tol=1e-3, loss=\"modified_huber\")   \n",
    "sgd_model2 = SGDClassifier(max_iter=8000, tol=1e-4, loss=\"modified_huber\", class_weight=\"balanced\") \n",
    "sgd_model3 = SGDClassifier(max_iter=10000, tol=5e-4, loss=\"modified_huber\", early_stopping=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36fa0db",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# Voting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58c6747",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-21T08:52:04.35359Z",
     "iopub.status.busy": "2023-11-21T08:52:04.353263Z",
     "iopub.status.idle": "2023-11-21T08:52:04.514361Z",
     "shell.execute_reply": "2023-11-21T08:52:04.513576Z",
     "shell.execute_reply.started": "2023-11-21T08:52:04.353561Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ensemble = VotingClassifier(estimators=[('lr',lr),('mnb',clf),('sgd', sgd_model),('sgd2', sgd_model2),('sgd3', sgd_model3)],weights=[0.01,0.06,0.31,0.31,0.31],voting='soft')\n",
    "ensemble.fit(X[:train.shape[0]], train.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97deafba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-21T08:52:04.516067Z",
     "iopub.status.busy": "2023-11-21T08:52:04.515721Z",
     "iopub.status.idle": "2023-11-21T08:52:04.522835Z",
     "shell.execute_reply": "2023-11-21T08:52:04.521916Z",
     "shell.execute_reply.started": "2023-11-21T08:52:04.516036Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "preds_test = ensemble.predict_proba(X[train.shape[0]:])[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c33fc1d3",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2ffbd2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-21T08:52:04.539111Z",
     "iopub.status.busy": "2023-11-21T08:52:04.53886Z",
     "iopub.status.idle": "2023-11-21T08:52:04.690928Z",
     "shell.execute_reply": "2023-11-21T08:52:04.689981Z",
     "shell.execute_reply.started": "2023-11-21T08:52:04.539089Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ntypos=test['text'].apply(lambda x: how_many_typos(x))\n",
    "test['ntypos'] = -ntypos\n",
    "test['generated'] = preds_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840cb367",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-21T08:52:04.694283Z",
     "iopub.status.busy": "2023-11-21T08:52:04.693772Z",
     "iopub.status.idle": "2023-11-21T08:52:04.708176Z",
     "shell.execute_reply": "2023-11-21T08:52:04.706946Z",
     "shell.execute_reply.started": "2023-11-21T08:52:04.694237Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({\n",
    "    'id': test[\"id\"],\n",
    "    'generated': test['generated']\n",
    "})\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7ece89",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 6888007,
     "sourceId": 61542,
     "sourceType": "competition"
    },
    {
     "datasetId": 3936750,
     "sourceId": 6847931,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 3945154,
     "sourceId": 6865136,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 3942644,
     "sourceId": 6890527,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 3961875,
     "sourceId": 6971638,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4005256,
     "sourceId": 6977472,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 150784240,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30579,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 58.079758,
   "end_time": "2023-11-22T06:33:52.169521",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-11-22T06:32:54.089763",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
